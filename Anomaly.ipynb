{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f24b20-8503-4cb0-9d2c-bc97be6291e4",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - $\\textit{Anomaly Detection}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3707fbb-caa7-4a98-8e41-184a71ddc381",
   "metadata": {},
   "source": [
    "## 1. Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aa07b0f-8ed1-491d-8eaf-c4af2312622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (0.21)\n",
      "Requirement already satisfied: xgboost in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from imbalanced-learn->imblearn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from imbalanced-learn->imblearn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\predator\\miniconda3\\envs\\d2l\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz\n",
    "!pip install xgboost\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "757b6e63-e7ce-40d9-9560-39b410b7f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 63257  100 63257    0     0   422k      0 --:--:-- --:--:-- --:--:--  431k\n"
     ]
    }
   ],
   "source": [
    "# Initialization: Load shared functions and simulated data \n",
    "\n",
    "# Load shared functions\n",
    "!curl -O https://raw.githubusercontent.com/Fraud-Detection-Handbook/fraud-detection-handbook/main/Chapter_References/shared_functions.py\n",
    "%run shared_functions.py\n",
    "\n",
    "# Get simulated data from Github repository\n",
    "if not os.path.exists(\"simulated-data-transformed\"):\n",
    "    !git clone https://github.com/Fraud-Detection-Handbook/simulated-data-transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654410c4-59ed-4cf9-8c2a-98e3915f01b3",
   "metadata": {},
   "source": [
    "$\\textit{Obs.: A saída está em vermelho, mas não indica erro.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa4dbf-0397-4eea-a348-7abb4319da83",
   "metadata": {},
   "source": [
    "## 2. Carregamento de dados (`Data Loading`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d25d4d-863e-4436-b72b-27d73746d371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load  files\n",
      "CPU times: total: 1.06 s\n",
      "Wall time: 2.17 s\n",
      "919767 transactions loaded, containing 8195 fraudulent transactions\n"
     ]
    }
   ],
   "source": [
    "DIR_INPUT='simulated-data-transformed/data/' \n",
    "\n",
    "BEGIN_DATE = \"2018-06-11\"\n",
    "END_DATE = \"2018-09-14\"\n",
    "\n",
    "print(\"Load  files\")\n",
    "%time transactions_df=read_from_files(DIR_INPUT, BEGIN_DATE, END_DATE)\n",
    "print(\"{0} transactions loaded, containing {1} fraudulent transactions\".format(len(transactions_df),transactions_df.TX_FRAUD.sum()))\n",
    "\n",
    "output_feature=\"TX_FRAUD\"\n",
    "\n",
    "input_features=['TX_AMOUNT','TX_DURING_WEEKEND', 'TX_DURING_NIGHT', 'CUSTOMER_ID_NB_TX_1DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW', 'CUSTOMER_ID_NB_TX_7DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW', 'CUSTOMER_ID_NB_TX_30DAY_WINDOW',\n",
    "       'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW', 'TERMINAL_ID_NB_TX_1DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_1DAY_WINDOW', 'TERMINAL_ID_NB_TX_7DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_7DAY_WINDOW', 'TERMINAL_ID_NB_TX_30DAY_WINDOW',\n",
    "       'TERMINAL_ID_RISK_30DAY_WINDOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490aeb95-5eb2-4061-9de6-9a836c0599d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the starting day for the training period, and the deltas\n",
    "start_date_training = datetime.datetime.strptime(\"2018-07-25\", \"%Y-%m-%d\")\n",
    "delta_train=7\n",
    "delta_delay=7\n",
    "delta_test=7\n",
    "\n",
    "\n",
    "delta_valid = delta_test\n",
    "\n",
    "start_date_training_with_valid = start_date_training+datetime.timedelta(days=-(delta_delay+delta_valid))\n",
    "\n",
    "(train_df, valid_df)=get_train_test_set(transactions_df,start_date_training_with_valid,\n",
    "                                       delta_train=delta_train,delta_delay=delta_delay,delta_test=delta_test)\n",
    "\n",
    "# By default, scales input data\n",
    "(train_df, valid_df)=scaleData(train_df, valid_df,input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107328e6-0cc9-4770-9baa-da30aac7b898",
   "metadata": {},
   "source": [
    "## 3. Implementação do Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af42ab6f-e465-4c35-8259-75546c0c8806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\" \n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "print(\"Selected device is\",DEVICE)\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3910354f-c16c-4dcd-a261-6dcc99345ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(train_df[input_features].values)\n",
    "x_valid = torch.FloatTensor(valid_df[input_features].values)\n",
    "y_train = torch.FloatTensor(train_df[output_feature].values)\n",
    "y_valid = torch.FloatTensor(valid_df[output_feature].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e012f884-d236-4a1f-8374-85cbbe213acc",
   "metadata": {},
   "source": [
    "Adaptação do Dataset para o Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add9eabd-1d1f-4ff3-a796-e06c7d992c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDatasetUnsupervised(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x,output=True):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.output = output\n",
    "\n",
    "    def __len__(self):\n",
    "        'Returns the total number of samples'\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample index\n",
    "        item = self.x[index].to(DEVICE)\n",
    "        if self.output:\n",
    "            return item, item\n",
    "        else:\n",
    "            return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8f06f77-5294-40e5-b725-83fcf1f27467",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = FraudDatasetUnsupervised(x_train)\n",
    "valid_set = FraudDatasetUnsupervised(x_valid)\n",
    "\n",
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size = 64) #Função para geração de DataLoaders a partir do dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86801f26-fa28-4183-8d55-e306eebdeb53",
   "metadata": {},
   "source": [
    "Autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c5876c-0bbc-4100-a0eb-fbecc73749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(torch.nn.Module):\n",
    "    \n",
    "        def __init__(self, input_size, intermediate_size, code_size):\n",
    "            super(SimpleAutoencoder, self).__init__()\n",
    "            # parameters\n",
    "            self.input_size = input_size\n",
    "            self.intermediate_size = intermediate_size           \n",
    "            self.code_size  = code_size\n",
    "            \n",
    "            self.relu = torch.nn.ReLU()   \n",
    "            \n",
    "            #encoder\n",
    "            self.fc1 = torch.nn.Linear(self.input_size, self.intermediate_size)\n",
    "            self.fc2 = torch.nn.Linear(self.intermediate_size, self.code_size)\n",
    "            \n",
    "            #decoder \n",
    "            self.fc3 = torch.nn.Linear(self.code_size, self.intermediate_size)            \n",
    "            self.fc4 = torch.nn.Linear(self.intermediate_size, self.input_size)\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            hidden = self.fc1(x)\n",
    "            hidden = self.relu(hidden)\n",
    "            \n",
    "            code = self.fc2(hidden)\n",
    "            code = self.relu(code)\n",
    " \n",
    "            hidden = self.fc3(code)\n",
    "            hidden = self.relu(hidden)\n",
    "            \n",
    "            output = self.fc4(hidden)\n",
    "            #linear activation in final layer)            \n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e4cd40c-f9ba-4119-badb-f9e6862cf150",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364c95f-cb91-4918-a540-71ac5997b6ac",
   "metadata": {},
   "source": [
    "## 4. Detecção de fraudes (não supervisionada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "047cf952-c963-43ea-baf2-e279c2a0395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_sample_mse(model, generator):\n",
    "    \n",
    "    model.eval()\n",
    "    criterion = torch.nn.MSELoss(reduction=\"none\")\n",
    "    batch_losses = []\n",
    "    \n",
    "    for x_batch, y_batch in generator:\n",
    "        # Forward pass\n",
    "        y_pred = model(x_batch)\n",
    "        # Compute Loss\n",
    "        loss = criterion(y_pred.squeeze(), y_batch)\n",
    "        loss_app = list(torch.mean(loss,axis=1).detach().cpu().numpy())\n",
    "        batch_losses.extend(loss_app)\n",
    "    \n",
    "    return batch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c89425c-ed76-4e53-ae52-fc293915fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "model = SimpleAutoencoder(x_train.shape[1], 100, 20).to(DEVICE)\n",
    "losses = per_sample_mse(model, valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6ca966-685a-4ecb-a20a-5be5c4bb39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6754841, 0.79146266, 1.1697072, 0.8070149, 1.258897]\n",
      "0.9325165\n"
     ]
    }
   ],
   "source": [
    "print(losses[0:5])\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67bc73-aeaf-49e9-9793-86691335814d",
   "metadata": {},
   "source": [
    "### 4.1 Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e08d0d2-e76e-4e38-8120-4ff4b5cb7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "\n",
    "training_generator,valid_generator = prepare_generators(training_set, valid_set, batch_size = 64)\n",
    "\n",
    "criterion = torch.nn.MSELoss().to(DEVICE)\n",
    "\n",
    "model = SimpleAutoencoder(len(input_features), 100,20).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34789136-67d1-487e-ad3c-5817f458bdfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0: train loss: 0.4457241622072219\n",
      "valid loss: 0.11789107639444331\n",
      "New best score: 0.11789107639444331\n",
      "\n",
      "Epoch 1: train loss: 0.08445224025594801\n",
      "valid loss: 0.044737972811760146\n",
      "New best score: 0.044737972811760146\n",
      "\n",
      "Epoch 2: train loss: 0.03813445719535931\n",
      "valid loss: 0.028129153183656313\n",
      "New best score: 0.028129153183656313\n",
      "\n",
      "Epoch 3: train loss: 0.02394556577707397\n",
      "valid loss: 0.016839738651255116\n",
      "New best score: 0.016839738651255116\n",
      "\n",
      "Epoch 4: train loss: 0.013857098703627006\n",
      "valid loss: 0.009604490618603152\n",
      "New best score: 0.009604490618603152\n",
      "\n",
      "Epoch 5: train loss: 0.007683125645078961\n",
      "valid loss: 0.005340869447389424\n",
      "New best score: 0.005340869447389424\n",
      "\n",
      "Epoch 6: train loss: 0.005279009854803876\n",
      "valid loss: 0.004115886983202129\n",
      "New best score: 0.004115886983202129\n",
      "\n",
      "Epoch 7: train loss: 0.004053559081707271\n",
      "valid loss: 0.003136056854486303\n",
      "New best score: 0.003136056854486303\n",
      "\n",
      "Epoch 8: train loss: 0.0030781877174595974\n",
      "valid loss: 0.0025031250393873113\n",
      "New best score: 0.0025031250393873113\n",
      "\n",
      "Epoch 9: train loss: 0.002489038441801198\n",
      "valid loss: 0.002192846600531188\n",
      "New best score: 0.002192846600531188\n",
      "\n",
      "Epoch 10: train loss: 0.0021340800122042715\n",
      "valid loss: 0.0018389495218152313\n",
      "New best score: 0.0018389495218152313\n",
      "\n",
      "Epoch 11: train loss: 0.0018568661446321621\n",
      "valid loss: 0.0016022739011432995\n",
      "New best score: 0.0016022739011432995\n",
      "\n",
      "Epoch 12: train loss: 0.0016325297950184681\n",
      "valid loss: 0.0014205192012172905\n",
      "New best score: 0.0014205192012172905\n",
      "\n",
      "Epoch 13: train loss: 0.0014396987664673556\n",
      "valid loss: 0.0012289095540210361\n",
      "New best score: 0.0012289095540210361\n",
      "\n",
      "Epoch 14: train loss: 0.0012724755787518567\n",
      "valid loss: 0.0010766992643170181\n",
      "New best score: 0.0010766992643170181\n",
      "\n",
      "Epoch 15: train loss: 0.0011277428504754478\n",
      "valid loss: 0.000967073216881664\n",
      "New best score: 0.000967073216881664\n",
      "\n",
      "Epoch 16: train loss: 0.0009995985445749001\n",
      "valid loss: 0.0008368678831195082\n",
      "New best score: 0.0008368678831195082\n",
      "\n",
      "Epoch 17: train loss: 0.0008799483916750284\n",
      "valid loss: 0.0007505903304859874\n",
      "New best score: 0.0007505903304859874\n",
      "\n",
      "Epoch 18: train loss: 0.0007859733865592347\n",
      "valid loss: 0.0006712928563203723\n",
      "New best score: 0.0006712928563203723\n",
      "\n",
      "Epoch 19: train loss: 0.0006957117962661193\n",
      "valid loss: 0.0006042739463896272\n",
      "New best score: 0.0006042739463896272\n",
      "\n",
      "Epoch 20: train loss: 0.0006247040317102244\n",
      "valid loss: 0.0005752739264334608\n",
      "New best score: 0.0005752739264334608\n",
      "\n",
      "Epoch 21: train loss: 0.0005639624898989701\n",
      "valid loss: 0.00045610128856096114\n",
      "New best score: 0.00045610128856096114\n",
      "\n",
      "Epoch 22: train loss: 0.000504718679157562\n",
      "valid loss: 0.00042793296673207905\n",
      "New best score: 0.00042793296673207905\n",
      "\n",
      "Epoch 23: train loss: 0.00045500604793505945\n",
      "valid loss: 0.0004357632225738136\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 24: train loss: 0.00041405958657780216\n",
      "valid loss: 0.00043886595293039793\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 25: train loss: 0.0003758992742114686\n",
      "valid loss: 0.0003434116847792773\n",
      "New best score: 0.0003434116847792773\n",
      "\n",
      "Epoch 26: train loss: 0.0003413291320041798\n",
      "valid loss: 0.00028342648626870063\n",
      "New best score: 0.00028342648626870063\n",
      "\n",
      "Epoch 27: train loss: 0.0003112982202996411\n",
      "valid loss: 0.0003034338932926512\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 28: train loss: 0.0002843810004272532\n",
      "valid loss: 0.00022372966475595207\n",
      "New best score: 0.00022372966475595207\n",
      "\n",
      "Epoch 29: train loss: 0.0002644067823909798\n",
      "valid loss: 0.00019793551773993206\n",
      "New best score: 0.00019793551773993206\n",
      "\n",
      "Epoch 30: train loss: 0.00023698542237465548\n",
      "valid loss: 0.00019993182668358067\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 31: train loss: 0.00022163121087747506\n",
      "valid loss: 0.0001944929967673185\n",
      "New best score: 0.0001944929967673185\n",
      "\n",
      "Epoch 32: train loss: 0.00020912930252558367\n",
      "valid loss: 0.0001553192996175685\n",
      "New best score: 0.0001553192996175685\n",
      "\n",
      "Epoch 33: train loss: 0.00019309651199527918\n",
      "valid loss: 0.00015392266929164258\n",
      "New best score: 0.00015392266929164258\n",
      "\n",
      "Epoch 34: train loss: 0.00018292420352051207\n",
      "valid loss: 0.00014851572393767963\n",
      "New best score: 0.00014851572393767963\n",
      "\n",
      "Epoch 35: train loss: 0.0001730198582472144\n",
      "valid loss: 0.00015366365659162605\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 36: train loss: 0.00016090276668724793\n",
      "valid loss: 0.00011859134704094377\n",
      "New best score: 0.00011859134704094377\n",
      "\n",
      "Epoch 37: train loss: 0.000146397821978867\n",
      "valid loss: 0.00011628808239893161\n",
      "New best score: 0.00011628808239893161\n",
      "\n",
      "Epoch 38: train loss: 0.00014250169776562697\n",
      "valid loss: 0.0001711507112120502\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 39: train loss: 0.00013660829325570125\n",
      "valid loss: 0.00011908631409436357\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 40: train loss: 0.0001277128293610636\n",
      "valid loss: 9.66945132287569e-05\n",
      "New best score: 9.66945132287569e-05\n",
      "\n",
      "Epoch 41: train loss: 0.00012306980455272716\n",
      "valid loss: 9.466443591376784e-05\n",
      "New best score: 9.466443591376784e-05\n",
      "\n",
      "Epoch 42: train loss: 0.00011739358845228409\n",
      "valid loss: 0.00010774780753134786\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 43: train loss: 0.00011063775263858763\n",
      "valid loss: 8.719407476329236e-05\n",
      "New best score: 8.719407476329236e-05\n",
      "\n",
      "Epoch 44: train loss: 0.00010661803785288103\n",
      "valid loss: 9.558068404608416e-05\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 45: train loss: 9.99634950047936e-05\n",
      "valid loss: 8.112984118061369e-05\n",
      "New best score: 8.112984118061369e-05\n",
      "\n",
      "Epoch 46: train loss: 9.609973409451188e-05\n",
      "valid loss: 8.116293923149733e-05\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 47: train loss: 9.0293156435271e-05\n",
      "valid loss: 7.552763005558598e-05\n",
      "New best score: 7.552763005558598e-05\n",
      "\n",
      "Epoch 48: train loss: 8.914725551750291e-05\n",
      "valid loss: 6.524447722131796e-05\n",
      "New best score: 6.524447722131796e-05\n",
      "\n",
      "Epoch 49: train loss: 8.500409600106566e-05\n",
      "valid loss: 8.57137513632124e-05\n",
      "1  iterations since best score.\n",
      "\n",
      "Epoch 50: train loss: 7.993586482275384e-05\n",
      "valid loss: 6.994430967226505e-05\n",
      "2  iterations since best score.\n",
      "\n",
      "Epoch 51: train loss: 7.67920650884295e-05\n",
      "valid loss: 7.206154973697823e-05\n",
      "3  iterations since best score.\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "model,training_execution_time,train_losses,valid_losses = training_loop(model,\n",
    "                                                                        training_generator,\n",
    "                                                                        valid_generator,\n",
    "                                                                        optimizer,\n",
    "                                                                        criterion,\n",
    "                                                                        max_epochs=500,\n",
    "                                                                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a375f-199d-42d1-9f03-20c90799b3ac",
   "metadata": {},
   "source": [
    "`Early Stopping` na época 51."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c2325-a01a-4acf-8e70-ec36ba828754",
   "metadata": {},
   "source": [
    "### 4.2 Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "932b7906-bddd-4542-8482-fa5f3343779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.35583e-05, 3.1533546e-05, 3.7850186e-05, 4.6781686e-05, 3.4615405e-05]\n",
      "7.209741e-05\n"
     ]
    }
   ],
   "source": [
    "losses = per_sample_mse(model, valid_generator)\n",
    "print(losses[0:5])\n",
    "print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4b1dbb6-3ca2-4482-b31d-cb35c8626f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1323, -0.6306,  2.1808, -0.3003,  0.1241, -1.6917,  0.5035, -1.6630,\n",
      "        -0.0482, -0.9810, -0.0816, -1.9895, -0.1231, -0.9719, -0.1436])\n",
      "tensor([-0.1370, -0.6276,  2.1797, -0.2948,  0.1179, -1.6992,  0.5020, -1.6770,\n",
      "        -0.0482, -0.9776, -0.0745, -1.9811, -0.1188, -0.9687, -0.1389],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(model(x_train[0].to(DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be482544-f4e5-4c37-b3c0-d79dc97e50c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average fraud reconstruction error: 0.0014036155\n",
      "Average genuine reconstruction error: 6.3530766e-05\n"
     ]
    }
   ],
   "source": [
    "genuine_losses = np.array(losses)[y_valid.cpu().numpy() == 0]\n",
    "fraud_losses = np.array(losses)[y_valid.cpu().numpy() == 1]\n",
    "print(\"Average fraud reconstruction error:\", np.mean(fraud_losses))\n",
    "print(\"Average genuine reconstruction error:\", np.mean(genuine_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1236ada-4e51-4833-a27f-9324e6ff47dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC ROC</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Card Precision@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.839</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AUC ROC  Average precision  Card Precision@100\n",
       "0    0.839              0.165               0.199"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df=valid_df\n",
    "predictions_df['predictions']=losses\n",
    "    \n",
    "performance_assessment(predictions_df, top_k_list=[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b116b5-3a45-466b-b810-5c31761f53e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
